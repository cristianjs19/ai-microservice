# --- Application Config ---
APP_NAME="Video AI Processor"
ENV="production"
LOG_LEVEL="INFO"
LOG_FORMAT="json"
SERVICE_NAME="ai-processing-service"

# --- Database (Postgres + PGVector) ---
# Note: In Docker, we use 'host.docker.internal' to access the DB running on your machine.
# If the DB was in a container, this would be 'postgres_container_name'.
DATABASE_URL="postgresql+asyncpg://your_user:your_password@host.docker.internal:5432/your_db_name"

# --- Message Broker (RabbitMQ) ---
# Note: 'rabbitmq' is the service name defined in docker-compose
RABBITMQ_URL="amqp://guest:guest@rabbitmq:5672/"
RABBITMQ_QUEUE_NAME="transcript.fetched"
RABBITMQ_DLQ_NAME="transcript.failed"
RABBITMQ_EXCHANGE="video.events"

# --- Fetching Service (yt-scraper) ---
FETCHING_SERVICE_URL="http://yt-scraper:8000"

# --- AI Provider (OpenRouter) ---
OPENROUTER_API_KEY="sk-or-v1-..."
# We override the Base URL so LangChain talks to OpenRouter instead of OpenAI
OPENROUTER_API_BASE="https://openrouter.ai/api/v1"

# --- Models ---
# Embedding: BAAI BGE Base v1.5 (768 Dimensions)
EMBEDDING_MODEL_NAME="baai/bge-base-en-v1.5"
EMBEDDING_DIMENSIONS=768
# LLM: The model used for the Agent/Formatting
LLM_MODEL_NAME="openai/gpt-oss-120b"
# Query Guardrail model (can be same as LLM)
QUERY_GUARDRAIL_MODEL="openai/gpt-oss-120b"

# --- Chunking Configuration ---
CHUNK_SIZE_TOKENS=400
CHUNK_OVERLAP_TOKENS=50

# --- RAG Configuration ---
RAG_TOP_K_DEFAULT=5
RAG_SIMILARITY_THRESHOLD_DEFAULT=0.7

# --- API Configuration ---
API_V1_PREFIX="/api/v1"
API_TITLE="AI Processing Service"
API_VERSION="2.1.0"

# --- JWT Authentication ---
# IMPORTANT: Generate a secure random key for production!
# You can generate one with: openssl rand -hex 32
JWT_SECRET_KEY="your-secret-key-change-this-in-production"
JWT_ALGORITHM="HS256"
JWT_ACCESS_TOKEN_EXPIRE_MINUTES=30
JWT_REFRESH_TOKEN_EXPIRE_DAYS=7