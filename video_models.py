"""Video related models for the AI Service."""

from __future__ import annotations

import uuid
from datetime import datetime
from enum import Enum
from typing import List, Optional

from sqlalchemy import (
    DateTime,
    ForeignKey,
    Index,
    Integer,
    String,
    Text,
    Enum as SAEnum,
)
from sqlalchemy.dialects.postgresql import UUID, JSONB
from sqlalchemy.orm import Mapped, mapped_column, relationship
from pgvector.sqlalchemy import Vector

from app.models.base import Base

# ---------------------------------------------------------
# Enums
# ---------------------------------------------------------


class ProcessingStatus(str, Enum):
    """Status of the AI processing pipeline for a video."""

    PENDING = "pending"  # Message received, not started
    PROCESSING = "processing"  # LLM is formatting / Embeddings being generated
    COMPLETED = "completed"  # Ready for RAG search
    FAILED = "failed"  # Error occurred


# ---------------------------------------------------------
# Models
# ---------------------------------------------------------


class VideoDocument(Base):
    """Represents a fully processed video transcript (The 'Parent')."""

    __tablename__ = "video_documents"

    id: Mapped[uuid.UUID] = mapped_column(
        UUID(as_uuid=True),
        primary_key=True,
        default=uuid.uuid4,
    )

    # Link to the external Fetching Service (Loose coupling)
    source_video_id: Mapped[str] = mapped_column(
        String(255),
        unique=True,
        nullable=False,
        index=True,
    )

    # Stored for RAG filtering
    source_channel_id: Mapped[Optional[str]] = mapped_column(
        String(255),
        index=True,
    )

    # The Human-Readable Article generated by the LLM
    formatted_content: Mapped[str] = mapped_column(Text, nullable=False)

    status: Mapped[ProcessingStatus] = mapped_column(
        SAEnum(ProcessingStatus, name="processing_status_enum"),
        default=ProcessingStatus.PENDING,
        nullable=False,
    )

    # Extra context (title, published_at, etc.)
    meta_data: Mapped[dict] = mapped_column(
        JSONB,
        default=dict,
        server_default="{}",
    )

    error_message: Mapped[Optional[str]] = mapped_column(Text)

    created_at: Mapped[datetime] = mapped_column(
        DateTime(timezone=True),
        default=datetime.utcnow,
    )
    updated_at: Mapped[datetime] = mapped_column(
        DateTime(timezone=True),
        default=datetime.utcnow,
        onupdate=datetime.utcnow,
    )

    # Relationship to children
    chunks: Mapped[List["VideoChunk"]] = relationship(
        "VideoChunk",
        back_populates="document",
        cascade="all, delete-orphan",
    )

    def __repr__(self) -> str:
        return f"<VideoDocument(id={self.id}, video_id={self.source_video_id}, status={self.status})>"


class VideoChunk(Base):
    """Represents a semantic vector chunk (The 'Child')."""

    __tablename__ = "video_chunks"

    id: Mapped[uuid.UUID] = mapped_column(
        UUID(as_uuid=True),
        primary_key=True,
        default=uuid.uuid4,
    )

    document_id: Mapped[uuid.UUID] = mapped_column(
        UUID(as_uuid=True),
        ForeignKey("video_documents.id", ondelete="CASCADE"),
        nullable=False,
    )

    # The specific text segment used for the embedding
    content: Mapped[str] = mapped_column(Text, nullable=False)

    chunk_index: Mapped[int] = mapped_column(Integer, nullable=False)

    # BAAI/bge-base-en-v1.5 = 768 dims
    embedding = mapped_column(Vector(768), nullable=False)

    # Relationship back to parent
    document: Mapped["VideoDocument"] = relationship(
        "VideoDocument",
        back_populates="chunks",
    )

    # HNSW Index for fast vector search
    __table_args__ = (
        Index(
            "idx_video_chunks_embedding",
            "embedding",
            postgresql_using="hnsw",
            postgresql_with={"m": 16, "ef_construction": 64},
        ),
    )

    def __repr__(self) -> str:
        return f"<VideoChunk(id={self.id}, index={self.chunk_index})>"
